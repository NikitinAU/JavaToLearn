## Алгоритм
конечная совокупность точно заданных правил решения некоторого класса задач или набор [инструкций](https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D0%B5%D1%80%D0%B0%D1%82%D0%BE%D1%80_(%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5) "Оператор (программирование)"), описывающих порядок действий исполнителя для решения определённой задачи. В старой трактовке вместо слова «порядок» использовалось слово «последовательность», но по мере развития [параллельности в работе компьютеров](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC "Параллельный алгоритм") слово «последовательность» стали заменять более общим словом «порядок». Независимые инструкции могут выполняться в произвольном порядке, параллельно, если это позволяют используемые исполнители.

## Структура данных
В информатике **структура данных** —  программная единица, позволяющая хранить и обрабатывать данные, а также обеспечивающая их эффективное использование. Данные при этом должны быть однотипными или логически связанными.

## Структуры данных (виды)

### Какие бывают?

  
**Линейные**, элементы образуют последовательность или линейный список, обход узлов линеен. Примеры: Массивы. Связанный список, стеки и очереди.  
  
**Нелинейные**, если обход узлов нелинейный, а данные не последовательны. Пример: граф и деревья.  
  

### Основные структуры данных.

  

1.  Массивы
2.  Стеки
3.  Очереди
4.  Связанные списки
5.  Графы
6.  Деревья
7.  Префиксные деревья
8.  Хэш таблицы

  

### Массивы

  
Массив — это самая простая и широко используемая структура данных. Другие структуры данных, такие как стеки и очереди, являются производными от массивов.  
  
Изображение простого массива размера 4, содержащего элементы (1, 2, 3 и 4).  
  
![](https://habrastorage.org/r/w1560/webt/iv/vj/kx/ivvjkxghqmm87r3ceaup-sjaxa8.jpeg)  
  
Каждому элементу данных присваивается положительное числовое значение (индекс), который соответствует позиции элемента в массиве. Большинство языков определяют начальный индекс массива как 0.  
  

#### Бывают

  
**Одномерные**, как показано выше.  
**Многомерные**, массивы внутри массивов.  
  

#### Основные операции

-   Insert-вставляет элемент по заданному индексу
-   Get-возвращает элемент по заданному индексу
-   Delete-удаление элемента по заданному индексу
-   Size-получить общее количество элементов в массиве
  

### Стеки

  
Стек — абстрактный тип данных, представляющий собой список элементов, организованных по принципу LIFO (англ. last in — first out, «последним пришёл — первым вышел»).  
  
Это не массивы. Это очередь. [Придумал Алан Тюринг.](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B5%D0%BA)  
  
Примером стека может быть куча книг, расположенных в вертикальном порядке. Для того, чтобы получить книгу, которая где-то посередине, вам нужно будет удалить все книги, размещенные на ней. Так работает метод LIFO (Last In First Out). Функция «Отменить» в приложениях работает по LIFO.  
  
Изображение стека, в три элемента (1, 2 и 3), где 3 находится наверху и будет удален первым.  
  
![](https://habrastorage.org/r/w1560/webt/vu/pp/hs/vupphsidgppdcjzld_h6haiohv8.jpeg)  
  

#### Основные операции


-   Push-вставляет элемент сверху
-   Pop-возвращает верхний элемент после удаления из стека
-   isEmpty-возвращает true, если стек пуст
-   Top-возвращает верхний элемент без удаления из стека


### Очереди

  
Подобно стекам, очередь — хранит элемент последовательным образом. Существенное отличие от стека – использование FIFO (First in First Out) вместо LIFO.  
  
Пример очереди – очередь людей. Последний занял последним и будешь, а первый первым ее и покинет.  
  
Изображение очереди, в четыре элемента (1, 2, 3 и 4), где 1 находится наверху и будет удален первым  
  
![](https://habrastorage.org/r/w1560/webt/vs/vz/d-/vsvzd-nhfbt8lgqygo_n6kevota.jpeg)  
  

#### Основные операции

  
-   Enqueue—) — вставляет элемент в конец очереди
-   Dequeue () — удаляет элемент из начала очереди
-   isEmpty () — возвращает значение true, если очередь пуста
-   Top () — возвращает первый элемент очереди
  

### Связанный список

  
Связанный список – массив где каждый элемент является отдельным объектом и состоит из двух элементов – данных и ссылки на следующий узел.  
  
Принципиальным преимуществом перед массивом является структурная гибкость: порядок элементов связного списка может не совпадать с порядком расположения элементов данных в памяти компьютера, а порядок обхода списка всегда явно задаётся его внутренними связями.  
  

#### Бывают

  
**Однонаправленный**, каждый узел хранит адрес или ссылку на следующий узел в списке и последний узел имеет следующий адрес или ссылку как NULL.  
  
1->2->3->4->NULL  
  
**Двунаправленный**, две ссылки, связанные с каждым узлом, одним из опорных пунктов на следующий узел и один к предыдущему узлу.  
  
NULL<-1<->2<->3->NULL  
  
**Круговой**, все узлы соединяются, образуя круг. В конце нет NULL. Циклический связанный список может быть одно-или двукратным циклическим связанным списком.  
  
1->2->3->1  
  
Самое частое, линейный однонаправленный список. Пример – файловая система.  
  
![](https://habrastorage.org/r/w1560/webt/ai/tc/0c/aitc0cr61ubeesbbvhicyx5xp3o.jpeg)  
  

#### Основные операции

  

-   InsertAtEnd — Вставка заданного элемента в конец списка
-   InsertAtHead — Вставка элемента в начало списка
-   Delete — удаляет заданный элемент из списка
-   DeleteAtHead — удаляет первый элемент списка
-   Search — возвращает заданный элемент из списка
-   isEmpty — возвращает True, если связанный список пуст


### Графы

  
Граф-это набор узлов (вершин), которые соединены друг с другом в виде сети ребрами (дугами).  
  
![](https://habrastorage.org/r/w1560/webt/9i/ul/cv/9iulcveuitlldkx6itsyprjcmhg.jpeg)  
  

#### Бывают

  
**Ориентированный**, ребра являются направленными, т.е. существует только одно доступное направление между двумя связными вершинами.  
**Неориентированные**, к каждому из ребер можно осуществлять переход в обоих направлениях.  
Смешанные  
  

#### Встречаются в таких формах как

  

-   Матрица смежности
-   Список смежности

  

#### Общие алгоритмы обхода графа

  

-   Поиск в ширину – обход по уровням
-   Поиск в глубину – обход по вершинам


### Деревья

  
Дерево-это иерархическая структура данных, состоящая из узлов (вершин) и ребер (дуг). Деревья по сути связанные графы без циклов.  
  
Древовидные структуры везде и всюду. Дерево скилов в играх знают все.  
  
Простое дерево  
  
![](https://habrastorage.org/r/w1560/webt/7u/ic/vv/7uicvvfrp5r11e6a_ysnnueynu8.jpeg)  
  
Типы деревьев  

-   N дерево
-   Сбалансированное дерево
-   [Бинарное дерево](https://habr.com/post/267855/)
-   Дерево Бинарного Поиска
-   [AVL дерево](https://habr.com/post/150732/)
-   [2-3-4 деревья](https://habr.com/post/273687/)

  
Бинарное дерево самое распространенное.  
  
_«Бинарное дерево — это иерархическая структура данных, в которой каждый узел имеет значение (оно же является в данном случае и ключом) и ссылки на левого и правого потомка. » — [Procs](https://habr.com/users/procs/)_  
  

#### Три способа обхода дерева

  

-   В прямом порядке (сверху вниз) — префиксная форма.
-   В симметричном порядке (слева направо) — инфиксная форма.
-   В обратном порядке (снизу вверх) — постфиксная форма.

### Trie ( префиксное деревое )

  
Разновидность дерева для строк, быстрый поиск. Словари. Т9.  
  
Вот как такое дерево хранит слова «top», «thus» и «their».  
  
![](https://habrastorage.org/r/w1560/webt/bg/ar/dz/bgardz981ki0zew8rybb7iui9iu.jpeg)  
  
Слова хранятся сверху вниз, зеленые цветные узлы «p», «s» и «r» указывают на конец «top», «thus « и «their» соответственно.  
  
### Хэш таблицы

  
Хэширование — это процесс, используемый для уникальной идентификации объектов и хранения каждого объекта в заранее рассчитанном уникальном индексе (ключе).  
  
Объект хранится в виде пары «ключ-значение», а коллекция таких элементов называется «словарем». Каждый объект можно найти с помощью этого ключа.  
  
По сути это массив, в котором ключ представлен в виде хеш-функции.  
  
Эффективность хеширования зависит от  
  

-   Функции хеширования
-   Размера хэш-таблицы
-   Метода борьбы с коллизиями

  
Пример сопоставления хеша в массиве. Индекс этого массива вычисляется через хэш-функцию.  
![](https://habrastorage.org/r/w1560/webt/gc/m7/tw/gcm7twadesefi0xzksi9e4gnjbw.jpeg)  

## Алгоритмы сортировок   
Во многом статья посвящена тому, как написать все алгоритмы и протестировать их. Если говорить о самом программировании, то иногда могут возникнуть совершенно неожиданные трудности (во многом благодаря оптимизатору C++). Однако не менее трудно решить, какие именно тесты и в каких количествах нужно сделать. Коды всех алгоритмов, которые выложены в данной статье, написаны мной. Доступны и результаты запусков на всех тестах. Единственное, что я не могу показать — это сами тесты, поскольку они весят почти 140 ГБ. При малейшем подозрении я проверял и код, соответствующий тесту, и сам тест. Надеюсь, что статья Вам понравится.  
  

### Описание основных сортировок и их реализация

  
Я постараюсь кратко и понятно описать сортировки и указать асимптотику, хотя последнее в рамках данной статьи не очень важно (интересно же узнать реальное время работы). О потреблении памяти в дальнейшем ничего писать не буду, замечу только, что сортировки, использующие непростые структуры данных (как, например, сортировка деревом), обычно потребляют ее в больших количествах, а остальные сортировки в худшем случае только создают вспомогательный массив. Также существует понятие стабильности (устойчивости) сортировки. Это значит, что относительный порядок элементов при их равенстве не меняется. Это тоже в рамках данной статьи неважно (в конце концов, можно просто прицепить к элементу его индекс), однако в одном месте пригодится.  
  

#### Сортировка пузырьком / Bubble sort

  
Будем идти по массиву слева направо. Если текущий элемент больше следующего, меняем их местами. Делаем так, пока массив не будет отсортирован. Заметим, что после первой итерации самый большой элемент будет находиться в конце массива, на правильном месте. После двух итераций на правильном месте будут стоять два наибольших элемента, и так далее. Очевидно, не более чем после n итераций массив будет отсортирован. Таким образом, асимптотика в худшем и среднем случае – O(n2), в лучшем случае – O(n).  


#### Шейкерная сортировка / Shaker sort

  
(также известна как сортировка перемешиванием и коктейльная сортировка). Заметим, что сортировка пузырьком работает медленно на тестах, в которых маленькие элементы стоят в конце (их еще называют «черепахами»). Такой элемент на каждом шаге алгоритма будет сдвигаться всего на одну позицию влево. Поэтому будем идти не только слева направо, но и справа налево. Будем поддерживать два указателя begin и end, обозначающих, какой отрезок массива еще не отсортирован. На очередной итерации при достижении end вычитаем из него единицу и движемся справа налево, аналогично, при достижении begin прибавляем единицу и двигаемся слева направо. Асимптотика у алгоритма такая же, как и у сортировки пузырьком, однако реальное время работы лучше.  
  

#### Сортировка расческой / Comb sort

  
Еще одна модификация сортировки пузырьком. Для того, чтобы избавиться от «черепах», будем переставлять элементы, стоящие на расстоянии. Зафиксируем его и будем идти слева направо, сравнивая элементы, стоящие на этом расстоянии, переставляя их, если необходимо. Очевидно, это позволит «черепахам» быстро добраться в начало массива. Оптимально изначально взять расстояние равным длине массива, а далее делить его на некоторый коэффициент, равный примерно 1.247. Когда расстояние станет равно единице, выполняется сортировка пузырьком. В лучшем случае асимптотика равна O(nlogn), в худшем – O(n2). Какая асимптотика в среднем мне не очень понятно, на практике похоже на O(nlogn).  
  
  

#### Сортировка вставками / Insertion sort

  
Создадим массив, в котором после завершения алгоритма будет лежать ответ. Будем поочередно вставлять элементы из исходного массива так, чтобы элементы в массиве-ответе всегда были отсортированы. Асимптотика в среднем и худшем случае – O(n2), в лучшем – O(n). Реализовывать алгоритм удобнее по-другому (создавать новый массив и реально что-то вставлять в него относительно сложно): просто сделаем так, чтобы отсортирован был некоторый префикс исходного массива, вместо вставки будем менять текущий элемент с предыдущим, пока они стоят в неправильном порядке.  
  

#### Сортировка Шелла / Shellsort

  
Используем ту же идею, что и сортировка с расческой, и применим к сортировке вставками. Зафиксируем некоторое расстояние. Тогда элементы массива разобьются на классы – в один класс попадают элементы, расстояние между которыми кратно зафиксированному расстоянию. Отсортируем сортировкой вставками каждый класс. В отличие от сортировки расческой, неизвестен оптимальный набор расстояний. Существует довольно много последовательностей с разными оценками. Последовательность Шелла – первый элемент равен длине массива, каждый следующий вдвое меньше предыдущего. Асимптотика в худшем случае – O(n2). Последовательность Хиббарда – 2n — 1, асимптотика в худшем случае – O(n1,5), последовательность Седжвика (формула нетривиальна, можете ее посмотреть по ссылке ниже) — O(n4/3), Пратта (все произведения степеней двойки и тройки) — O(nlog2n). Отмечу, что все эти последовательности нужно рассчитать только до размера массива и запускать от большего от меньшему (иначе получится просто сортировка вставками). Также я провел дополнительное исследование и протестировал разные последовательности вида si = a * si — 1 + k * si — 1 (отчасти это было навеяно эмпирической последовательностью Циура – одной из лучших последовательностей расстояний для небольшого количества элементов). Наилучшими оказались последовательности с коэффициентами a = 3, k = 1/3; a = 4, k = 1/4 и a = 4, k = -1/5.  
  

[Сортировка Шелла в англоязычной Википедии](https://en.wikipedia.org/wiki/Shellsort)  

  

#### Сортировка деревом / Tree sort

  
Будем вставлять элементы в двоичное дерево поиска. После того, как все элементы вставлены достаточно обойти дерево в глубину и получить отсортированный массив. Если использовать сбалансированное дерево, например красно-черное, асимптотика будет равна O(nlogn) в худшем, среднем и лучшем случае. В реализации использован контейнер multiset.  
  
Здесь можно почитать про деревья поиска:  
  
[Википедия](https://ru.wikipedia.org/wiki/%D0%94%D0%B2%D0%BE%D0%B8%D1%87%D0%BD%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0)  
[Статья на Хабре](https://habrahabr.ru/post/65617/)  

#### Гномья сортировка / Gnome sort

  
Алгоритм похож на сортировку вставками. Поддерживаем указатель на текущий элемент, если он больше предыдущего или он первый — смещаем указатель на позицию вправо, иначе меняем текущий и предыдущий элементы местами и смещаемся влево.  


#### Сортировка выбором / Selection sort

  
На очередной итерации будем находить минимум в массиве после текущего элемента и менять его с ним, если надо. Таким образом, после i-ой итерации первые i элементов будут стоять на своих местах. Асимптотика: O(n2) в лучшем, среднем и худшем случае. Нужно отметить, что эту сортировку можно реализовать двумя способами – сохраняя минимум и его индекс или просто переставляя текущий элемент с рассматриваемым, если они стоят в неправильном порядке. Первый способ оказался немного быстрее, поэтому он и реализован.  


#### Пирамидальная сортировка / Heapsort

  
Развитие идеи сортировки выбором. Воспользуемся структурой данных «куча» (или «пирамида», откуда и название алгоритма). Она позволяет получать минимум за O(1), добавляя элементы и извлекая минимум за O(logn). Таким образом, асимптотика O(nlogn) в худшем, среднем и лучшем случае. Реализовывал кучу я сам, хотя в С++ и есть контейнер priority_queue, поскольку этот контейнер довольно медленный.  
  
Почитать про кучу можно здесь:  
  
[Википедия](https://ru.wikipedia.org/wiki/%D0%9A%D1%83%D1%87%D0%B0_(%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85))  
[Статья на Хабре](https://habrahabr.ru/post/112222/)  


#### Быстрая сортировка / Quicksort

  
Выберем некоторый опорный элемент. После этого перекинем все элементы, меньшие его, налево, а большие – направо. Рекурсивно вызовемся от каждой из частей. В итоге получим отсортированный массив, так как каждый элемент меньше опорного стоял раньше каждого большего опорного. Асимптотика: O(nlogn) в среднем и лучшем случае, O(n2). Наихудшая оценка достигается при неудачном выборе опорного элемента. Моя реализация этого алгоритма совершенно стандартна, идем одновременно слева и справа, находим пару элементов, таких, что левый элемент больше опорного, а правый меньше, и меняем их местами. Помимо чистой быстрой сортировки, участвовала в сравнении и сортировка, переходящая при малом количестве элементов на сортировку вставками. Константа подобрана тестированием, а сортировка вставками — наилучшая сортировка, подходящая для этой задачи (хотя не стоит из-за этого думать, что она самая быстрая из квадратичных).  
  

#### Сортировка слиянием / Merge sort

  
Сортировка, основанная на парадигме «разделяй и властвуй». Разделим массив пополам, рекурсивно отсортируем части, после чего выполним процедуру слияния: поддерживаем два указателя, один на текущий элемент первой части, второй – на текущий элемент второй части. Из этих двух элементов выбираем минимальный, вставляем в ответ и сдвигаем указатель, соответствующий минимуму. Слияние работает за O(n), уровней всего logn, поэтому асимптотика O(nlogn). Эффективно заранее создать временный массив и передать его в качестве аргумента функции. Эта сортировка рекурсивна, как и быстрая, а потому возможен переход на квадратичную при небольшом числе элементов.  
  

#### Сортировка подсчетом / Counting sort

  
Создадим массив размера r – l, где l – минимальный, а r – максимальный элемент массива. После этого пройдем по массиву и подсчитаем количество вхождений каждого элемента. Теперь можно пройти по массиву значений и выписать каждое число столько раз, сколько нужно. Асимптотика – O(n + r — l). Можно модифицировать этот алгоритм, чтобы он стал стабильным: для этого определим место, где должно стоять очередное число (это просто префиксные суммы в массиве значений) и будем идти по исходному массиву слева направо, ставя элемент на правильное место и увеличивая позицию на 1. Эта сортировка не тестировалась, поскольку большинство тестов содержало достаточно большие числа, не позволяющие создать массив требуемого размера. Однако она, тем не менее, пригодилась.  
  

#### Блочная сортировка / Bucket sort

  
(также известна как корзинная и карманная сортировка). Пусть l – минимальный, а r – максимальный элемент массива. Разобьем элементы на блоки, в первом будут элементы от l до l + k, во втором – от l + k до l + 2k и т.д., где k = (r – l) / количество блоков. В общем-то, если количество блоков равно двум, то данный алгоритм превращается в разновидность быстрой сортировки. Асимптотика этого алгоритма неясна, время работы зависит и от входных данных, и от количества блоков. Утверждается, что на удачных данных время работы линейно. Реализация этого алгоритма оказалась одной из самых трудных задач. Можно сделать это так: просто создавать новые массивы, рекурсивно их сортировать и склеивать. Однако такой подход все же довольно медленный и меня не устроил. В эффективной реализации используется несколько идей:  
  
1) Не будем создавать новых массивов. Для этого воспользуемся техникой сортировки подсчетом – подсчитаем количество элементов в каждом блоке, префиксные суммы и, таким образом, позицию каждого элемента в массиве.  
  
2) Не будем запускаться из пустых блоков. Занесем индексы непустых блоков в отдельный массив и запустимся только от них.  
  
3) Проверим, отсортирован ли массив. Это не ухудшит время работы, так как все равно нужно сделать проход с целью нахождения минимума и максимума, однако позволит алгоритму ускориться на частично отсортированных данных, ведь элементы вставляются в новые блоки в том же порядке, что и в исходном массиве.  
  
4) Поскольку алгоритм получился довольно громоздким, при небольшом количестве элементов он крайне неэффективен. До такой степени, что переход на сортировку вставками ускоряет работу примерно в 10 раз.  
  
Осталось только понять, какое количество блоков нужно выбрать. На рандомизированных тестах мне удалось получить следующую оценку: 1500 блоков для 107 элементов и 3000 для 108. Подобрать формулу не удалось – время работы ухудшалось в несколько раз.  
  

#### Поразрядная сортировка / Radix sort

  
(также известна как цифровая сортировка). Существует две версии этой сортировки, в которых, на мой взгляд, мало общего, кроме идеи воспользоваться представлением числа в какой-либо системе счисления (например, двоичной).  
  

###### LSD (least significant digit):

  
Представим каждое число в двоичном виде. На каждом шаге алгоритма будем сортировать числа таким образом, чтобы они были отсортированы по первым k * i битам, где k – некоторая константа. Из данного определения следует, что на каждом шаге достаточно стабильно сортировать элементы по новым k битам. Для этого идеально подходит сортировка подсчетом (необходимо 2k памяти и времени, что немного при удачном выборе константы). Асимптотика: O(n), если считать, что числа фиксированного размера (а в противном случае нельзя было бы считать, что сравнение двух чисел выполняется за единицу времени). Реализация довольно проста.  
   

###### MSD (most significant digit):

  
На самом деле, некоторая разновидность блочной сортировки. В один блок будут попадать числа с равными k битами. Асимптотика такая же, как и у LSD версии. Реализация очень похожа на блочную сортировку, но проще. В ней используется функция digit, определенная в реализации LSD версии.
## BIG O - Сам расскажешь))

## Linear and Binary Search
##### Линейный поиск в массиве

Очень часто требуется найти в массиве заданное значение или сообщить, что его там нет. Для этого нужно просмотреть все элементы массива с первого до последнего. Как только будет найден элемент, равный заданному значению `X`, надо завершить поиск и вывести результат. Такой алгоритм называется **линейным.**  
  
Линейный алгоритм используют для поиска максимального (минимального) элемента массива. Это тоже алгоритм поиска. Но здесь мы вынуждены идти до конца массива, т.к. необходимо сравнивать все элементы, с текущим значением максимума (минимума) и в случае если текущий элемент больше (меньше) значения максимума (минимума) заменять значение максимума (минимума).   

Возможен еще один подход к решению этой задачи. Можно использовать досрочный выход из цикла, если найдено требуемое значение.   
В С++ для досрочного выхода из цикла используется оператор break;

##### Двоичный поиск

Двоичный (или бинарный) поиск является эффективным алгоритмом поиска, выполняется он быстрее чем линейный поиск. Например, для массива из 1024 элементов линейный поиск в худшем случае (когда искомого элемента нет в массиве) обработает все 1024 элемента, но бинарным поиском достаточно обработать 10 элементов. Такой результат достигается за счет того, что после первого шага цикла область поиска сужается до 512 элементов, после второго – до 256 и т.д.

Недостатками такого алгоритма является требование упорядоченности данных, а также возможности доступа к любому элементу данных за постоянное (не зависящее от количества данных) время. Таким образом алгоритм не может работать на неупорядоченных массивах.  
 

###### Алгоритм

1.  Выбрать средний элемент `A[c]` и сравнить с `X`.
2.  Если `X = A[c]`, то нашли (стоп).
3.  Если `X < A[c]`, искать дальше в первой половине.
4.  Если `X > A[c]`, искать дальше во второй половине.